{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN（畳み込みニューラルネットワーク）の基礎\n",
    "\n",
    "このノートブックでは、画像分類の数理的基礎を学びます。\n",
    "\n",
    "## 目次\n",
    "1. 画像データの構造\n",
    "2. なぜCNNが必要か？（特徴量の保持）\n",
    "3. CNNの全体像\n",
    "4. 各層の役割\n",
    "5. 手書き数字分類（MNIST）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 画像データの構造\n",
    "\n",
    "画像データは**ピクセル**（画素）と呼ばれる微小な四角形の集合体です。\n",
    "\n",
    "| 画像タイプ | データ構造 | ピクセル値 |\n",
    "|-----------|-----------|----------|\n",
    "| グレースケール | 2次元 (H, W) | 0（黒）〜 255（白）|\n",
    "| カラー（RGB） | 3次元 (H, W, 3) | 各チャンネル 0〜255 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 図3.2: グレースケール画像のピクセル値の例（教科書より）\n",
    "# 0〜255の値で濃淡を表現\n",
    "pixel_example = np.array([\n",
    "    [0,   85,  170],\n",
    "    [255, 50,  100],\n",
    "    [150, 200, 225]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 左: ピクセル値を数値で表示\n",
    "ax1 = axes[0]\n",
    "ax1.imshow(pixel_example, cmap='gray', vmin=0, vmax=255)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax1.text(j, i, str(pixel_example[i, j]), \n",
    "                ha='center', va='center', fontsize=16,\n",
    "                color='white' if pixel_example[i, j] < 128 else 'black')\n",
    "ax1.set_title('グレースケール画像のピクセル値\\n(0=黒, 255=白)', fontsize=12)\n",
    "ax1.axis('off')\n",
    "\n",
    "# 右: グラデーションバー\n",
    "ax2 = axes[1]\n",
    "gradient = np.linspace(0, 255, 256).reshape(1, -1).astype(np.uint8)\n",
    "ax2.imshow(np.repeat(gradient, 50, axis=0), cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('ピクセル値と濃淡の対応', fontsize=12)\n",
    "ax2.set_xlabel('0 (黒) ←――――――→ 255 (白)')\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. なぜCNNが必要か？（特徴量の保持）\n",
    "\n",
    "### 問題：画像データを直接1次元に変換すると情報が失われる\n",
    "\n",
    "画像分類の最終段階では**ソフトマックス関数**を使いますが、この関数は**1次元データ**を必要とします。\n",
    "\n",
    "しかし、画像データは2次元（または3次元）構造を持っており、単純に1次元に変換すると**重要な特徴量**を失う可能性があります。\n",
    "\n",
    "### 特徴量とは？\n",
    "\n",
    "**特徴量**とは、画像が持つ意味のある情報です：\n",
    "- ピクセルの数値そのもの\n",
    "- ピクセル集合同士の**近さ/遠さ**（空間的関係）\n",
    "\n",
    "**例：顔認識**\n",
    "- 人の顔は「目、鼻、口」が特徴\n",
    "- これらは2次元平面で**一定の距離内に集まっている**\n",
    "- 目、鼻、口は**上から下に並んでいる**\n",
    "\n",
    "→ この空間的な位置関係こそが重要な特徴量！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の重要性を示す例\n",
    "# 同じピクセル値でも配置が違えば全く別の画像になる\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# 元の画像（8の形）\n",
    "original = np.array([\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 1, 1, 1, 0]\n",
    "]) * 255\n",
    "\n",
    "# 1次元に変換して再配置（ランダム）\n",
    "flat = original.flatten()\n",
    "np.random.seed(42)\n",
    "shuffled = flat.copy()\n",
    "np.random.shuffle(shuffled)\n",
    "randomized = shuffled.reshape(5, 5)\n",
    "\n",
    "axes[0].imshow(original, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('元の画像「8」\\n（空間構造あり）', fontsize=11)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].bar(range(25), flat, color='steelblue')\n",
    "axes[1].set_title('1次元に変換\\n（空間情報が失われる）', fontsize=11)\n",
    "axes[1].set_xlabel('インデックス')\n",
    "axes[1].set_ylabel('ピクセル値')\n",
    "\n",
    "axes[2].imshow(randomized, cmap='gray', vmin=0, vmax=255)\n",
    "axes[2].set_title('シャッフル後\\n（同じピクセル値、違う意味）', fontsize=11)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"→ 単純に1次元化すると、形状（空間的特徴）の情報が失われる！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNNの全体像\n",
    "\n",
    "CNNは**形状を保持しながら**特徴を抽出し、最終的に1次元に変換します。\n",
    "\n",
    "```\n",
    "入力層 → [畳み込み層 → プーリング層] × N → 全結合層 → 出力層\n",
    "  ↓           ↓              ↓              ↓          ↓\n",
    " 画像      特徴抽出       サイズ圧縮      1次元化    確率出力\n",
    "(2D/3D)    (2D/3D)        (2D/3D)        (1D)       (1D)\n",
    "```\n",
    "\n",
    "**ポイント**: 畳み込みとプーリングを繰り返すことで、空間構造を保ちながら徐々に特徴を圧縮していく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 各層の役割\n",
    "\n",
    "| 層 | 処理内容 | 入出力 |\n",
    "|---|---------|-------|\n",
    "| **入力層** | 画像データを受け取る | → 2D/3D |\n",
    "| **畳み込み層** | フィルタで積和演算、特徴を抽出 | 2D/3D → 特徴マップ |\n",
    "| **プーリング層** | 特徴マップのサイズを縮小（データ量削減） | 特徴マップ → 小さい特徴マップ |\n",
    "| **全結合層** | すべての特徴量を1次元に配列 | 2D/3D → 1D |\n",
    "| **出力層** | ソフトマックス関数で確率を出力 | 1D → 分類結果 |\n",
    "\n",
    "### CNNの名前の由来\n",
    "- **C**NN = **C**onvolutional Neural Network\n",
    "- **Convolutional** = 畳み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNの処理フローを視覚化\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# 1. 入力画像\n",
    "input_img = np.random.randint(0, 255, (28, 28))\n",
    "axes[0].imshow(input_img, cmap='gray')\n",
    "axes[0].set_title('入力層\\n(28×28)', fontsize=10)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. 畳み込み後\n",
    "conv1 = np.random.randint(0, 255, (24, 24))\n",
    "axes[1].imshow(conv1, cmap='Blues')\n",
    "axes[1].set_title('畳み込み層\\n(24×24)\\n特徴抽出', fontsize=10)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 3. プーリング後\n",
    "pool1 = np.random.randint(0, 255, (12, 12))\n",
    "axes[2].imshow(pool1, cmap='Blues')\n",
    "axes[2].set_title('プーリング層\\n(12×12)\\nサイズ圧縮', fontsize=10)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 4. 全結合層\n",
    "fc = np.random.rand(1, 50)\n",
    "axes[3].imshow(fc, cmap='Oranges', aspect='auto')\n",
    "axes[3].set_title('全結合層\\n(1×N)\\n1次元化', fontsize=10)\n",
    "axes[3].axis('off')\n",
    "\n",
    "# 5. 出力層\n",
    "output = np.zeros(10)\n",
    "output[8] = 0.95  # \"8\"の確率が高い\n",
    "axes[4].bar(range(10), output, color='green')\n",
    "axes[4].set_title('出力層\\n(確率分布)\\nソフトマックス', fontsize=10)\n",
    "axes[4].set_xticks(range(10))\n",
    "axes[4].set_xlabel('クラス (0-9)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 手書き数字分類（MNIST）\n",
    "\n",
    "MNISTデータセット：28×28ピクセルのグレースケール手書き数字（0〜9）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータセットの読み込み\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# データの前処理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST用の正規化\n",
    "])\n",
    "\n",
    "# データセットのダウンロード\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(f\"訓練データ: {len(train_dataset)} 枚\")\n",
    "print(f\"テストデータ: {len(test_dataset)} 枚\")\n",
    "print(f\"画像サイズ: {train_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル画像の表示\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_dataset[i]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'ラベル: {label}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('MNISTデータセットのサンプル', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "1. **画像データ**はピクセルの2D/3D配列で、0〜255の値で濃淡/色を表現\n",
    "2. **特徴量**（空間的な位置関係）を保持することが画像認識で重要\n",
    "3. **CNN**は畳み込み→プーリングを繰り返し、形状を保ちながら特徴を抽出\n",
    "4. 最終的に**全結合層**で1次元化し、**ソフトマックス**で確率を出力\n",
    "\n",
    "## 次のステップ\n",
    "\n",
    "次のノートブックでは、**畳み込み演算**の数理について詳しく学びます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
